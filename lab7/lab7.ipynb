{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnlearn as bn\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "import os, contextlib\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "p_input = {\n",
    "    'studies' : [[0.36], [0.64]],\n",
    "    'loneliness' : [[0.85], [0.15]],\n",
    "    'overeating' : [[0.85, 0.35, 0.7, 0.15],\n",
    "                    [0.15, 0.65, 0.3, 0.85]],\n",
    "    'depression' : [[0.8, 0.3], [0.2, 0.7]]\n",
    "}\n",
    "\n",
    "edges_input = {\n",
    "    'studies' : 'overeating',\n",
    "    'loneliness' : 'overeating',\n",
    "    'overeating' : 'depression'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >bayes DAG created.\n",
      "[bnlearn] >No changes made to existing bayes DAG.\n",
      "[bnlearn] >Add CPD: studies\n",
      "[bnlearn] >Add CPD: loneliness\n",
      "[bnlearn] >Add CPD: overeating\n",
      "[bnlearn] >Add CPD: depression\n",
      "[bnlearn] >Checking CPDs..\n",
      "[bnlearn] >Check for DAG structure. Correct: True\n"
     ]
    }
   ],
   "source": [
    "edges = [(edge, edges_input[edge]) for edge in edges_input]\n",
    "unconditional_nodes = [node for node in edges_input if node not in edges_input.values()]\n",
    "cpds = []\n",
    "for node in unconditional_nodes:\n",
    "    cpds.append(TabularCPD(variable=node, variable_card=2, values=p_input[node]))\n",
    "for node in p_input:\n",
    "    if node not in unconditional_nodes:\n",
    "        evidence = [edge[0] for edge in edges if edge[1] == node]\n",
    "        cpds.append(TabularCPD(variable=node, variable_card=2, values=p_input[node], evidence=evidence, evidence_card=[2]*len(evidence)))\n",
    "\n",
    "DAG = bn.make_DAG(edges)\n",
    "DAG = bn.make_DAG(DAG, CPD=cpds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.devnull, 'w') as devnull:\n",
    "    with contextlib.redirect_stdout(devnull):\n",
    "        with open('out.csv', 'w', newline = '') as outFile:\n",
    "            writer = csv.DictWriter(outFile, fieldnames=p_input.keys())\n",
    "            writer.writeheader()\n",
    "            for n in range(N):\n",
    "                row = {}\n",
    "                for node in unconditional_nodes:\n",
    "                    row[node] = np.random.binomial(1, p_input[node][1][0])\n",
    "                for node in p_input:\n",
    "                    if node not in unconditional_nodes:\n",
    "                        evidence = {}\n",
    "                        for edge in edges:\n",
    "                            if edge[1] == node:\n",
    "                                evidence[edge[0]] = row[edge[0]]\n",
    "                        cond_p = bn.inference.fit(DAG, variables=[node], evidence=evidence).df['p'][1]\n",
    "                        row[node] = np.random.binomial(1, cond_p)\n",
    "                writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(out_filename):\n",
    "    with open(out_filename, newline ='') as outFile:\n",
    "        output = csv.DictReader(outFile)\n",
    "        fieldnames = output.fieldnames\n",
    "        p = {}\n",
    "        dist_p = {}\n",
    "        diff_p = {}\n",
    "        for field_name in fieldnames:\n",
    "            p[field_name] = 0\n",
    "            dist_p[field_name] = bn.inference.fit(DAG, variables=[field_name], evidence={}).df['p'][1]\n",
    "        for line in output:\n",
    "            for field_name in fieldnames:\n",
    "                p[field_name] += int(line[field_name])\n",
    "        for key in p:\n",
    "            p[key] = p[key] / N\n",
    "        print('From data:')\n",
    "        print(p)\n",
    "        print('From distribition:')\n",
    "        print(dist_p)\n",
    "        for field_name in fieldnames:\n",
    "            diff_p[field_name] = abs(p[field_name] - dist_p[field_name])\n",
    "        print('Difference:')\n",
    "        print(diff_p)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------+\n",
      "|    |   studies |    p |\n",
      "+====+===========+======+\n",
      "|  0 |         0 | 0.36 |\n",
      "+----+-----------+------+\n",
      "|  1 |         1 | 0.64 |\n",
      "+----+-----------+------+\n",
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+------+\n",
      "|    |   loneliness |    p |\n",
      "+====+==============+======+\n",
      "|  0 |            0 | 0.85 |\n",
      "+----+--------------+------+\n",
      "|  1 |            1 | 0.15 |\n",
      "+----+--------------+------+\n",
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|██████████| 2/2 [00:00<00:00, 212.45it/s]\n",
      "Eliminating: loneliness: 100%|██████████| 2/2 [00:00<00:00, 353.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+--------+\n",
      "|    |   overeating |      p |\n",
      "+====+==============+========+\n",
      "|  0 |            0 | 0.6742 |\n",
      "+----+--------------+--------+\n",
      "|  1 |            1 | 0.3258 |\n",
      "+----+--------------+--------+\n",
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "Eliminating: loneliness: 100%|██████████| 3/3 [00:00<00:00, 303.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+--------+\n",
      "|    |   depression |      p |\n",
      "+====+==============+========+\n",
      "|  0 |            0 | 0.6371 |\n",
      "+----+--------------+--------+\n",
      "|  1 |            1 | 0.3629 |\n",
      "+----+--------------+--------+\n",
      "From data:\n",
      "{'studies': 0.59, 'loneliness': 0.18, 'overeating': 0.37, 'depression': 0.4}\n",
      "From distribition:\n",
      "{'studies': 0.64, 'loneliness': 0.15, 'overeating': 0.3258, 'depression': 0.3629}\n",
      "Difference:\n",
      "{'studies': 0.050000000000000044, 'loneliness': 0.03, 'overeating': 0.04420000000000002, 'depression': 0.03710000000000002}\n",
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Eliminating: loneliness: 100%|██████████| 2/2 [00:00<00:00, 182.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+\n",
      "|    |   overeating |        p |\n",
      "+====+==============+==========+\n",
      "|  0 |            0 | 0.371562 |\n",
      "+----+--------------+----------+\n",
      "|  1 |            1 | 0.628438 |\n",
      "+----+--------------+----------+\n",
      "P(depression|overeating) from data:\n",
      "0.7000000000000001\n",
      "P(depression|overeating) from distribution:\n",
      "0.6284375861118764\n",
      "P(depression|overeating) difference\n",
      "0.07156241388812368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p = check_output('out.csv')\n",
    "\n",
    "dist_p_depression_overeating = bn.inference.fit(DAG, variables=['overeating'], evidence={'depression' : 1}).df['p'][1]\n",
    "\n",
    "p_depression_overeating = 0\n",
    "with open('out.csv', newline ='') as outFile:\n",
    "    output = csv.DictReader(outFile)\n",
    "    for line in output:\n",
    "        if int(line['depression']) == 1:\n",
    "            p_depression_overeating += int(line['overeating'])\n",
    "p_depression_overeating = p_depression_overeating/N/p['depression']\n",
    "\n",
    "\n",
    "print(\"P(depression|overeating) from data:\")\n",
    "print(p_depression_overeating)\n",
    "print(\"P(depression|overeating) from distribution:\")\n",
    "print(dist_p_depression_overeating)\n",
    "print(\"P(depression|overeating) difference\")\n",
    "print(abs(p_depression_overeating - dist_p_depression_overeating))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43fc3a0df826a7cb1348a3bf3d71824a64c2f0de5f295c676d2b275b77c08f2e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
